---
layout: post
title: Kafka
date: 2020-02-07 13:33:31
categories: bigdata
share: y
excerpt_separator: <!--more-->
---


<!--more-->

## 1. 生产者
1. Java版本的客户端和服务端的处理器，都使用了Selector模式和KafkaChannel，而Scala版本的客户端则使用比较原始的BlockingChannel。
2. 在C/S的通信模型中，一个client会连接多个server，一个server也会接收多个client的连接，所以使用selector模式可以使网络通信更加高效。
3. 另外，我们在server端运用了Reactor模式，将网络请求和业务处理的线程进行分离。
4. 除此之外，客户端和服务端在很多地方都运用了队列这种数据结构，来对请求或者响应进行排队。

在client要向server发送消息时，我们会获取cluster集群状态（Java版本）或集群元数据TopicMetadata（Scala版本），并为消息选择分区，选择分区的主副本作为目标节点。在服务端，SocketServer会接收客户端发送的请求交给请求处理线程和KafkaApis处理。具体和消息相关的处理逻辑，由KafkaApis以及KafkaServer中的其他组件一起完成。

Producer和Consumer都不是Kafka的内置服务，而是一种客户端（所以它们都在client包中）。客户端可以独立于Kafka集群，因此开发客户端应用程序需要提供一个kafka集群的地址。

## 2. 消费者
### 2.1 消费者线程模型
客户端创建基于ZK的**消费者连接器**，ZK作为共享存储保存了kafka集群或者客户端的相关信息，比如topic、消费者和消费组的关系、分区和消费者的关系、分区的偏移量等。连接器是消费者进程的入口，根据客户端订阅的topic和设置的线程数，从而引入了**消费者的线程模型**。一个消费者客户端是一个Java进程，消费者可以订阅多个主题，甚至每个主题可以自定义线程数，消费者实际上是个多线程的程序。Java的多线程通常需要考虑加锁同步方案对线程和数据进行隔离，但是kafka消费者的多线程比较简单，以为一个消费者的多个线程处理的分区是互斥的，不存在同一个分区被相同线程处理的情况，所以不需要数据共享。

为什么需要记录消费者和消费组的关系？

所有消费者祖晨一个消费组共同消费订阅topic的所有分区，假设所有分区都平均分配给所有的消费者，每个消费者有了独一无二的分区，接着就可以拉取自己负责的分区消息，并消费拉取到的消息。还有消费者的故障容错机制，消费者可能挂掉，或者有新的消费者加入消费组。当出现消费者增减时，消费组会收集所有的消费者，将分区重新分配给现存活的消费者，这个操作叫“再平衡”，消费组的每个消费者都会发生再平衡。每个消费者在启动时，会往ZK的消费组节点下添加一个子节点，表示自己要加入这个消费组。

消费者线程要拉取分区消息，需要确定分区的主副本节点，kafka针对分区有一个限制条件：客户端针对分区的读写请求，只能发生在分区的主副本上。一个消息代理节点会存储多个分区，有可能消费者负责的分区中，有几个分区的主副本是在同一个节点上的。为了减少客户端的网络连接数量，连接到同一个目标节点的多个分区可以合并起来一起处理。就像生产者对消息按照分区的主副本分组后，相同主副本的多个分区只以一个请求的方式，通过一个网络连接发送到一个目标节点。

每个消费者可以拉取多个分区，拉取到消息后如何暴露给客户端应用程序？客户端是不是应该不停地监听消费者的拉取线程，如果没有新消息就等待？这种**不同步的工作模式**一般使用队列来暂存数据，并对数据的产生和获取进行解耦。拉取线程将拉取到的消息放入队列，消费线程从队列中弹出消息处理，它们之间没有很强的依赖关系。这两个线程除了操作队列还会更新相应的状态信息，所以引出了**分区信息对象（PartitionTopicInfo）**。拉取线程要更新分区信息的拉取状态（fetchOffset），消费线程要更新分区信息的消费状态（consumedOffset）。分配给消费者的每个分区都对应一个分区信息，不同的分区可以共用一个分区信息的队列。

队列作为拉取消息的存储介质，这种底层的数据结构不适合直接暴露给客户端应用程序，所以引出了“消息流”对队列进行了包装。消费者拉取线程每次可以拉取多个分区，每个分区都会对应队列中的一个数据块，每个数据块都包含一个消息集。客户端为了获取每条消息，首先从队列里弹出一个数据块，然后读取数据集的每条消息。为了尽量保持客户端API的简单，消息流实现了Iterable接口，对应的消费者迭代器会负责从队列中读取消息块，最后生成消息集对应的迭代器给客户端使用。

客户端消费完消息，会定时地提交消费进度到ZK或者以消息形式发送到kafka集群的内部主题节点，这样的节点叫作“消费组的协调者（GroupCoordinator）”或“偏移量管理器（OffsetManager）”。偏移量消息内容的键是“消费组、主题、分区”。

### 2.2 再平衡和分区分配

使用高级API，每个消费者进程启动时都会创建一个消费者连接器，并在ZK中注册消费者成员变化、分区变化的监听器。一旦监听器注册的事件被触发，就会被ZKRebalanceListener的再平衡方法，为消费组的所有消费者重新分配分区。为了保证整个消费组分区分配算法的一致性，当一个消费者加入消费组触发再平衡，该消费组内的所有消费者会同时触发再平衡。

由于每个消费者的再平衡都是独立的进程，消费者之间并不知道其他消费者的再平衡最后有没有成功。可能有些消费者再平衡成功了，有些却失败了，就会导致本来分配给这个消费者的分区，因为再平衡失败而无法被消费，但是其他消费者又都无法知晓。解决这个问题的方法是：在服务端为每个消费组都选举一个协调节点，让它负责某个消费组中所有消费者的协调工作。另外，消费者提交分区的偏移量也是写到协调节点上的。**实际上，消费者客户端发送给服务端的请求“只要和消费组有关，都会被协调节点处理”**。具体步骤如下：

1. 每个消费者触发再平衡时都和协调者联系，由协调者执行全局的分区分配。
2. 协调者分配完成后，将分区分配给每个消费者。
3. 每个消费者收到任务列表后，启动拉取线程，拉取对应分区的消息，并更新拉取状态。
4. 消费者周期性提交分区的偏移量给协调者，协调者将分区偏移量写到内部主题。

再平衡操作需要从ZK读取所有存活的消费者，没有协调节点，每个消费者都要执行分区的分配算法，并从全局的分配结果中获取属于当前消费者的分区。而有了协调者节点后，只有协调者节点才会执行分区分配算法，每个消费者不需要和ZK进行通信，它们只要接收协调者节点分配的任务即可。

## 3 新消费者


![](../images/高级api和新api的主要流程和相关组件.png)

消费者消费消息主要和KafkaConsumer类进行交互。客户端通过subscribe()方法订阅指定的主题，然后调用poll()方法轮询。轮询主要分为3个步骤： 

1. 消费者拉取器发送拉取请求
2. 通过消费者的网络客户端轮询
3. 从拉取器中获取拉取结果

下面列举了消费者消费消息，以及发生再平衡操作时的具体步骤：

1. 消费者分配到分区，订阅状态中的分区状态，初始时还没有拉取偏移量。
2. 客户端轮询为没有拉取偏移量的分区更新位置，会尝试从服务端协调节点读取分区的提交偏移量
3. 由于此时没有记录分区的提交偏移量，只能按照客户端设置的重置策略定位到最早或最近的位置
4. 消费者根据分区的拉取偏移量，从分区的主副本节点拉取消息，并更新分区状态的拉取偏移量
5. 分区有了偏移量，自动提交偏移量的定时任务开始工作
6. 定时提交任务会将分区状态最新的拉群偏移量提交到服务端
7. 如果分区所有权没有发生变化，下次拉取消息时，已经存在拉取偏移量的分区不需要更新位置
8. 如果分区所有权发生变化，协调者会将分区重新分配给新的消费者
9. 新消费者之前没有分配该分区，会从服务端读取其他消费者之前提交的分区偏移量
10. 新消费者从分区最近的提交偏移量拉取数据，而且它的定时任务会提交偏移量到服务端
11. 协调者确保分区一定会分配给消费者，这样让分区一定会被消费者拉取并被消费。

客户端在发送请求后返回一个异步请求对象，表示客户端会在为了某个时刻收到服务端返回的响应结果。客户端可以在返回的异步请求上添加一个监听器，当异步请求完成时，就会自动触发监听器的回调方法。异步请求还有其他高级的用法，比如组合模式、链接模式。组合模式返回的是一个新的异步请求，也可以在这个异步请求再添加一个监听器，形成组合加监听器模式。使用异步请求的步骤有3：

1. 调用发送请求返回异步请求
2. 客户端轮询
3. 获取异步请求的结果

客户端轮询有3种方式：

1. 快速轮询，调用该方法后会立即返回到主程序，这是无阻塞的轮询
2. 带超时时间的轮询，如果在给定时间内没有结果返回，会返回到主线程，这是阻塞的轮询
3. 没有时间限制的轮询，只有在异步请求完成后才会返回到主线程，这是阻塞的轮询

客户端发送请求得到的异步请求，它的泛型烈性是客户端响应（ClientResponse）。使用“组合+适配器”模式后，可以将客户端响应转换为自定义的类型。比如获取分区的偏移量（LIST_OFFSET）返回的异步请求对象是RequestFuture<Long>，获取分区的提交偏移量（OFFSET_FETCH）对应类型是Map<TopicPartition, OffsetAndMetadata>，加入消费组对应类型是ByteBuffer，心跳和自动提交任务对应类型是RequestFuture<Void>。下面列举了使用异步请求的3种做法，最后都要获取异步请求的结果，用于回调处理。

1. 客户端使用组合模式发送请求，返回异步请求对象后，立即调用client.poll(future)进行阻塞式地轮询操作。客户端只有在异步请求完成的时候，才可以获取异步请求的结果：

```
//客户端发送请求返回异步请求对象，先轮询，等异步请求完成，再获取结果
RequestFuture<ByteBuffer> future = client.send(req).compose(adapter)
client.poll(future);
if (future.succeeded()) {
	handleResponse(future.value);
}
```

2.  为客户端发送请求返回的异步请求对象添加一个监听器，然后才开始阻塞式地轮询。异步请求监听器回调方法的蚕食是客户端响应对象，当客户端收到服务端的响应结果后，会先将客户端的响应结果设置为异步请求对象的结果值，然后调用监听器的回调方法。

```
//客户端发送请求返回异步请求对象，先添加监听器再轮询，等收到客户端响应后，触发回调
RequestFuture<ByteBuffer> future = client.send(req)
future.addListener(new RequestFutureListener<ClientResponse>) {
	public void onSuccess(ClientResponse value) {
		handleResponse(value);
	}
}
client.poll(future);
```

3. 客户端使用组合模式发送请求，并给返回的异步请求对象添加一个监听器，然后开始阻塞式的轮询。相当于组合了前两种模式，它和第二种模式的区别是异步请求的类型为ByteBuffer而不是客户端响应。和第二组组长一样，最后都会调用异步请求监听器的回调。

```
RequestFuture<ByteBuffer> future = client.send(req).compose(adapter)
future.addListener(new RequestFutureListener<ByteBuffer>) {
	public void onSuccess(ByteBuffer value) {
		handleResponse(value);
	}
}
client.poll(future);
```

以组合模式的异步请求为例，客户端发送请求并获取响应结果的具体步骤如下：

1. 客户端调用sendRequest()向服务端节点发送请求
2. 客户端不需要等待服务端返回结果，返回异步请求
3. 在2返回的异步请求上添加一个监听器
4. 客户端在异步请求轮询，会阻塞式地等待请求完成
5. 如果异步请求完成，则继续轮询
6. 当收到服务端返回的响应结果后，调用handleResponse()回调方法
7. 在回调方法中会解析出客户端响应，调用异步请求的complete()方法，完成异步请求
8. 从客户端响应对象解析出来的数据，会被设置为异步请求的结果值
9. 客户端调用异步请求的value()方法，获取异步请求的结果。

## 4 协调者
新的消费者将“消费者管理协议”和“分区分配策略”进行了分离。协调者仍然负责消费组的管理，包括消费者元数据、消费组元数据、消费组状态机等数据结构的维护。而分区分配的实现则会在消费组的一个主消费者中完成。由于分区分交由主消费者客户端完成，但每个消费者为了获得分区分配结果，还是只能和协调者联系，因此主消费者在完成分区分配后，还要将分配结果发送回协调者。

采用这种方式，每个消费者都需要发送下面两种请求给协调者：

- 加入组请求。协调者收集消费组的所有消费者，并选举一个主消费者执行分区分配操作
- 同步组请求。主消费者完成分区分配，由协调者将分区的分配结果传播给每个消费者。

消费者发送“加入组请求”给协调者，是为了让协调者收集所有的消费者。协调者会把消费者成员列表发送给主消费者，这样主消费者才可以执行分区分配工作。每个消费者发送给协调者的“加入组请求”，都带有各自的消费者成员元数据。比如，消费者订阅的主题、消费者编号、会话超时时间等。

主消费者收到“加入组响应”带有所有消费者成员，它在执行完分区分配工作后，发送给协调者的“同步组请求”带有分配给每个消费者的分区结果。协调者在收到后，会先将消费组的分配结果持久化，然后才返回“同步组响应”给每个消费者。

消费者发送“同步组请求”，是在它收到协调者的“加入组响应”后才开始的，“加入组请求”和“同步组请求”链式依次调用。

协调者除了管理消费者的负载均衡，并最终分配分区给每个消费者，还会接收每个消费者的心跳请求。协调者通过心跳监控消费者成员是否存活。

## 5 存储层

日志存储、日志管理、副本管理器。日志存储会将消息集写到底层的日志文件，它的主要概念如下：

1. 一个日志（Log）有多个日志分段（LogSegment）。每个日志分段由数据文件（FileMessage）和索引文件（OffsetIndex）组成。
2. 偏移量是消息最重要的组成部分。每条消息写入底层数据文件，都会有一个递增的偏移量。
3. 索引文件保存了消息偏移量到物理位置的映射关系，但并不是保存数据文件的所有消息，而是建个一定数量的消息才保存一条映射关系。索引文件保存的偏移量是相对偏移量，数据文件中每条消息的偏移量是分区基本的绝对偏移量。
4. 存储索引文件的条目时，将绝对偏移量-日志分段的基准偏移量。查询索引文件返回的相对偏移量+基准偏移量才能拥有查询数据文件。
5. 客户端每次读取数据文件，服务端都会创建一个文件视图，文件视图和底层文件数据文件公用一个文件通道，但拥有不同的开始位置和结束位置。
6. 服务端返回文件视图给客户端，采用零拷贝技术，将底层文件通道的数据直接传输到网络通道。

日志管理器管理了服务端的所有日志，除了上面对日志的追加和读取操作外，日志管理还有下面几个后台管理的线程类。

- 定时将数据文件写到磁盘上、定时将恢复点写入检查点文件
- 日志清理线程根据日志的大小和时间清理最旧的日志分段
- 日志压缩线程将相同键的不同消息进行压缩，压缩线程将日志按照清理点分成头部和尾部

副本管理器保存了服务端的所有分区，并处理客户端发送的读写请求：

- 副本管理器处理读写请求，会先操作分区的主副本。appendMessage()方法会将消息集写入主副本的本地日志，fetchMessage()方法会从主副本的本地日志读取消息集。
- 每个分区都有一个主副本和多个备份副本，只有主副本才有日志对象。副本有两个重要的位置信息：LEO表示副本的最新偏移量，HW表示副本的最高水位。
- 生成请求的应答值（acks）需要服务端创建延迟的生成（DelayedProduce）,拉取请求的最少字节数（fetchMinBytes）需要服务端创建延迟的拉取（DelayedFetch）。
- 延迟缓存会记录分区到延迟操作的映射关系，外部事件会根据分区尝试完成延迟的操作。
- 延迟缓存有监视器、清理器、定时器协调完成延迟的操作。

## 6 控制器
控制器是kafka副本机制的核心。如何将一个分区的多个副本以分布式的方式存储在不同的消息代理节点上，这就是控制器的主要职责。

kafka集群的元数据信息会持久化到ZK中，kafka控制器需要和ZK进行交互，获取分区的副本集合（AR）、主副本（Leader）、同步的副本集（ISR）。新创建主题时，kafka控制器会从每个分区的AR中选举主副本，并下发LeaderAndIsr请求给分区所有副本所在的代理节点。在主题数据变化时，kafka控制器有不同的主副本选举策略。

控制器内部的主要组件包括多种类型的监听器，它们分别注册到不同的ZK节点，监控不同的外部事件，比如：代理节点上下线、分区数变化、重新分区等。kafka控制器使用了 分区状态机 和 副本状态机 处理分区和副本的状态变化，状态包括：“不存在”， “新建”， “上线”， “下线”。删除主题时，副本状态机还引入了“开始删除”， “删除成功”，“删除失败”三个状态。状态机的状态转换都有一定的规则，比如：删除主题时，副本状态要从“下线”到“不存在”，中间必须经过“开始删除”， “删除成功”。

分区状态机 和 副本状态机 处理状态转换事件时，都有不同的事件处理逻辑。涉及分区状态变化的事件，控制器最后都会发送LeaderAndIsr请求给分区对应的代理节点，并发送UpdateMetadata请求给所有的代理节点。以用户创建主题为例，分析kafka集群的主要处理流程：

1. 用户新创建主题，会在ZK中创建一个主题节点，节点的数据包括所有的分区和分区的所有副本集。
2. kafka控制器的监听器（TopicChangeListener）会出发分区状态机和副本状态机的事件处理
3. 分区状态机会为分区选举主副本，并在ZK中创建分区节点，数据包括分区的主副本、ISR集合。
4. 控制器发送LeaderAndIsr请求给分区的所有副本，不同副本可以成为主副本、备份副本

为了维护kafka集群的稳定性和可用性，控制器要处理各种各样的异常情况，比如：代理节点挂掉会对上面有主副本的分区产生影响、代理节点重启后增加了可用的副本。另外，控制器还要处理一些管理工作，比如重新分配分区、选举最优副本平和分区、删除主题等。

控制器一个很重要的工作是决定了分区的主副本后，要将LeaderAndIsr请求下发给受影响的代理节点。每个收到LeaderAndIsr请求的代理节点，都会根据分区在当前节点是“主副本”还是“备份副本”，分别调用分区的makeLeader()或者makeFollower()方法。

控制器除了发送LeaderAndIsr请求给部分代理节点，还会发送UpdateMetadata请求给所有的代理节点。元数据包括分区状态数据、存活的代理节点，每个代理节点都会缓存元数据到MetadataCache对象中。元数据的缓存在每个代理节点都是一致的，客户端在需要查询主题元数据（TopicMetadata）时，发送元数据请求（Metadata）只需要连接任意一个节点。

从上面的分析中可以知道，控制器下发LeaderAndIsr请求、UpdateMetadata请求，以及客户端发送元数据请求获取TopicMetadata数据、客户端往分区的主副本写入数据这几个过程都是有序的。

## 7 基于Kafka构建数据流管道

在实际运用中，不同数据源与kafka集群的数据同步也非常重要。kafka连接器为源系统导入到kafka定义了源连接器（SourceConnector），为数据从kafka导入到目标系统定义了目标连接器（SinkConnector）。它们底层通过源任务（SourceTask）和目标任务（SinkTask）执行具体的数据同步逻辑。

为了支持单机模式和分布式模式，kafka连接器提供了Header作为框架的入口，并用worker进程来管理当前节点上的连接器实例和任务线程。与源系统相关的worker组件有源连接器（WorkerConnector）和源任务线程（WorkerSourceTask）,与目标系统相关的Worker组件有目标连接器（WorkerSinkConnector）和目标任务线程（WokerSinkTask）。源任务线程调用源任务（SourceTask）的poll()方法轮询源系统，目标任务线程调用目标任务（SinkTask）的put()推送数据到目标系统。源任务线程将源记录发送到kafka，目标任务从kafka轮询数据都是在kafka框架内部完成的。

单机模式下，kafka连接器  的所有内部组件都在一个JVM进程中运行，单机模式只会启动一个worker，这个worker管理了所有的连接器与任务。分布式模式下，不同的worker组成了一个kafka连接器集群，每个节点都会启动一个worker进程，每个worker分别管理一部分连接器与任务。分布式模式下，不同worker进程之间的协调工作类似于消费者的协调。worker也通过协调者获取分配的连接器和任务。


